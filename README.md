# OVCD-RSIL
Vision-Language Model Guidance Remote Sensing Instance Learning Makes Better Open-Vocabulary Change Detector  
  
The paper is under review and the code will be released soon...

### Abstract
Change detection (CD) is a crucial task for analyzing the impacts of anthropogenic and ecological changes on Earth’s land cover. Recently, vision–language models (VLMs) have driven progress in open-vocabulary tasks. However, VLMs trained mainly on natural images captured from horizontal viewpoints and on image-level remote sensing images (RSIs) struggle to perform well in fine-grained open-vocabulary change detection (OVCD) from satellite bird’s-eye views. In addition to offering more precise boundary delineation than image-level data, remote sensing (RS) instances are decoupled from the original RSIs, enabling more convenient and cost-effective acquisition compared to pixel-level data. Therefore, to fully leverage RS instances in numerous unregistered single-temporal RSIs, we introduce a remote sensing instance learning paradigm (RSIL). Specifically, we first extract RS instances via a proposed instance- and pixel-level mining strategy and inject layer-sensitive low-rank matrices into VLMs as additional trainable parameters for domain adaptation. Further, we employ a Gaussian Mixture Model to capture the distribution of instance losses, and reassign pseudo-labels to high-loss, low-confidence instances. Finally, leveraging the visual priors of VLMs and the adapted knowledge from the instances, we propose a holistic OVCD framework, namely OVCD-RSIL. We conducted extensive OVCD experiments on building, land cover, and semantic CD datasets. Without relying on original CD labels or any auxiliary data, OVCD-RSIL attains state-of-the-art (SOTA) performance in OVCD.
